{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmark_ForwardBackward",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# this notebook is running on google colab"
      ],
      "metadata": {
        "id": "ofLDl9-FNxN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "using Pkg\n",
        "Pkg.status()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqO8ykVmNadM",
        "outputId": "bd5d54bf-ac5c-4c75-c551-7271c6c7b8c9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39mBenchmarkTools v1.3.1\n",
            " \u001b[90m [052768ef] \u001b[39mCUDA v3.9.0\n",
            " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.3\n",
            " \u001b[90m [b8d414a4] \u001b[39mPaddleChainRules v0.1.0 `https://github.com/songjhaha/PaddleChainRules.jl.git#main`\n",
            " \u001b[90m [438e738f] \u001b[39mPyCall v1.93.1\n",
            " \u001b[90m [e88e6eb3] \u001b[39mZygote v0.6.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erJ7bkEtLrCF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e61c44e-9a2a-4cb9-c4c8-60196647ad08"
      },
      "source": [
        "using PyCall\n",
        "# install paddle-gpu\n",
        "run(`$(PyCall.pyprogramname) -m pip install paddlepaddle-gpu`)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: paddlepaddle-gpu in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (1.21.5)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (0.8.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (7.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (4.4.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (3.17.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4m/usr/bin/python3\u001b[24m \u001b[4m-m\u001b[24m \u001b[4mpip\u001b[24m \u001b[4minstall\u001b[24m \u001b[4mpaddlepaddle-gpu\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu information\n",
        "run(`lscpu`)"
      ],
      "metadata": {
        "id": "AWrg3vEGK1EH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57aa8d59-71b4-48a1-c2e3-596f37ccfb17"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2299.998\n",
            "BogoMIPS:            4599.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4mlscpu\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpu information\n",
        "run(`nvidia-smi`)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnFliSRuL0s1",
        "outputId": "28c8aa3c-7513-43ad-a72a-de95db962d67"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 16 03:35:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    72W / 149W |    949MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4mnvidia-smi\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using PaddleChainRules.Paddle: paddle, PaddleModuleWrapper, PaddleStatelessModule, ispysetup\n",
        "using BenchmarkTools\n",
        "using Zygote\n",
        "using CUDA\n",
        "\n",
        "if !ispysetup[]\n",
        "    return\n",
        "end\n",
        "\n",
        "function forward_pass!(s, indim, outdim, hiddendim, dummyinput, batchsize, device; samples=100, evals=10)\n",
        "    if device == \"cuda\"\n",
        "        paddle.device.set_device(\"gpu:0\")\n",
        "    else\n",
        "        paddle.device.set_device(\"cpu\")\n",
        "    end\n",
        "    ml = paddle.nn.Sequential(paddle.nn.Linear(indim, hiddendim), paddle.nn.ReLU(), paddle.nn.Linear(hiddendim, outdim))\n",
        "    mlfun = PaddleStatelessModule(ml)\n",
        "    pyparams = deepcopy(ml.parameters())\n",
        "    mlfun2 = x->mlfun(pyparams, x)\n",
        "\n",
        "    mlwrap = PaddleModuleWrapper(deepcopy(ml))\n",
        "\n",
        "    \n",
        "    inshape = size(dummyinput)\n",
        "\n",
        "    pyinputs = paddle.randn((batchsize, inshape...))\n",
        "    jlinputs = randn(Float32, reverse(inshape)..., batchsize)\n",
        "    if device == \"cuda\"\n",
        "        jlinputs = CUDA.cu(jlinputs)\n",
        "    end\n",
        "\n",
        "\n",
        "    ## Paddle\n",
        "    b_paddle = @benchmarkable($ml(x), setup=(x=$pyinputs), samples=samples, evals=evals)\n",
        "\n",
        "    ## FuncPaddle\n",
        "    b_funcpaddle = @benchmarkable($mlfun2(x), setup=(x=$pyinputs), samples=samples, evals=evals)\n",
        "\n",
        "    ## PaddleModuleWrapper\n",
        "    b_jl = @benchmarkable($mlwrap(x), setup=(x=$jlinputs), samples=samples, evals=evals)\n",
        "    \n",
        "    \n",
        "    s[\"paddle\"] = b_paddle\n",
        "    s[\"funcpaddle\"] = b_funcpaddle\n",
        "    s[\"jl\"] = b_jl\n",
        "end\n",
        "\n",
        "function backward_pass!(s, indim, outdim, hiddendim, dummyinput, batchsize, device; samples=100, evals=10)\n",
        "    if device == \"cuda\"\n",
        "        paddle.device.set_device(\"gpu:0\")\n",
        "    else\n",
        "        paddle.device.set_device(\"cpu\")\n",
        "    end\n",
        "    ml = paddle.nn.Sequential(paddle.nn.Linear(indim, hiddendim), paddle.nn.ReLU(), paddle.nn.Linear(hiddendim, outdim))\n",
        "    mlfun = PaddleStatelessModule(ml)\n",
        "    pyparams = deepcopy(ml.parameters())\n",
        "\n",
        "    mlwrap = PaddleModuleWrapper(deepcopy(ml))\n",
        "\n",
        "\n",
        "    inshape = size(dummyinput)\n",
        "\n",
        "    pyinputs = paddle.randn((batchsize, inshape...))\n",
        "    jlinputs = randn(Float32, reverse(inshape)..., batchsize)\n",
        "    if device == \"cuda\"\n",
        "        jlinputs = CUDA.cu(jlinputs)\n",
        "    end\n",
        "\n",
        "    ## Paddle\n",
        "    paddlegrad = (m, x)->paddle.grad(paddle.sum(m(x)), m.parameters())\n",
        "    b_paddle = @benchmarkable($paddlegrad(m, x), setup=(m=$ml; x=$pyinputs), samples=samples, evals=evals)\n",
        "\n",
        "    ## Funcpaddle\n",
        "    funcgrad = (params, x)->paddle.grad(paddle.sum(mlfun(params, x)), params)\n",
        "    b_funcpaddle = @benchmarkable($funcgrad(params, x), setup=(params=$pyparams; x=$pyinputs), samples=samples, evals=evals)\n",
        "\n",
        "    ## PaddleModuleWrapper\n",
        "    zygotegrad = (m, x) -> Zygote.gradient(m->sum(m(x)), m)\n",
        "    b_jl = @benchmarkable($zygotegrad(m, x), setup=(m=$mlwrap; x=$jlinputs), samples=samples, evals=evals)\n",
        "    \n",
        "    s[\"paddle\"] = b_paddle\n",
        "    s[\"funcpaddle\"] = b_funcpaddle\n",
        "    s[\"jl\"] = b_jl\n",
        "end"
      ],
      "metadata": {
        "id": "20utWs3aAYCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6700db7b-a0bc-4500-c148-d0e82f136246"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "backward_pass! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchsizes = [1, 8, 16, 32]\n",
        "indim = 8\n",
        "outdim = 4\n",
        "hiddendim = 64\n",
        "\n",
        "suite = BenchmarkGroup()"
      ],
      "metadata": {
        "id": "n_HXk42GAbwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce28d324-14c6-4596-e183-d7be5dcafe08"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for device in [\"cpu\", \"cuda\"]\n",
        "    ss = suite[\"$device\"] = BenchmarkGroup()\n",
        "    for batchsize in batchsizes\n",
        "        s = ss[\"bs=$batchsize\"] = BenchmarkGroup()\n",
        "        # Forward pass\n",
        "        s[\"forward\"] = BenchmarkGroup()\n",
        "        forward_pass!(s[\"forward\"], indim, outdim, hiddendim, randn(Float32, indim), batchsize, device)\n",
        "\n",
        "        # Gradient pass\n",
        "        s[\"backward\"] = BenchmarkGroup()\n",
        "        backward_pass!(s[\"backward\"], indim, outdim, hiddendim, randn(Float32, indim), batchsize, device)\n",
        "    end\n",
        "end"
      ],
      "metadata": {
        "id": "NwgkdUAEAexJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a long time\n",
        "tune!(suite)"
      ],
      "metadata": {
        "id": "BVOLsmbDArGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e7571a-2f1f-4be6-cf2e-69398719071e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []\n",
              "  \"cpu\" => 4-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"bs=16\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"bs=32\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"bs=8\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"bs=1\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "  \"cuda\" => 4-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"bs=16\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"bs=32\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"bs=8\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"bs=1\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"jl\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t\t\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = run(suite, verbose = false)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa-hmGICBJ1Q",
        "outputId": "b4776871-901f-44ec-f6f2-06ce1ce29f62"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []\n",
              "  \"cpu\" => 4-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"bs=16\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(310.671 μs)\n",
              "\t\t\t  \"jl\" => Trial(752.794 μs)\n",
              "\t\t\t  \"paddle\" => Trial(270.323 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(853.963 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.749 ms)\n",
              "\t\t\t  \"paddle\" => Trial(864.520 μs)\n",
              "\t  \"bs=32\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(319.946 μs)\n",
              "\t\t\t  \"jl\" => Trial(763.199 μs)\n",
              "\t\t\t  \"paddle\" => Trial(270.306 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(870.366 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.778 ms)\n",
              "\t\t\t  \"paddle\" => Trial(918.160 μs)\n",
              "\t  \"bs=8\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(302.661 μs)\n",
              "\t\t\t  \"jl\" => Trial(846.044 μs)\n",
              "\t\t\t  \"paddle\" => Trial(273.180 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(847.601 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.765 ms)\n",
              "\t\t\t  \"paddle\" => Trial(910.554 μs)\n",
              "\t  \"bs=1\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(318.776 μs)\n",
              "\t\t\t  \"jl\" => Trial(761.947 μs)\n",
              "\t\t\t  \"paddle\" => Trial(294.913 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(947.146 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.801 ms)\n",
              "\t\t\t  \"paddle\" => Trial(868.599 μs)\n",
              "  \"cuda\" => 4-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"bs=16\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(311.631 μs)\n",
              "\t\t\t  \"jl\" => Trial(751.089 μs)\n",
              "\t\t\t  \"paddle\" => Trial(273.112 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(884.187 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.761 ms)\n",
              "\t\t\t  \"paddle\" => Trial(928.658 μs)\n",
              "\t  \"bs=32\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(311.554 μs)\n",
              "\t\t\t  \"jl\" => Trial(804.851 μs)\n",
              "\t\t\t  \"paddle\" => Trial(263.674 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(879.314 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.777 ms)\n",
              "\t\t\t  \"paddle\" => Trial(891.787 μs)\n",
              "\t  \"bs=8\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(303.128 μs)\n",
              "\t\t\t  \"jl\" => Trial(745.190 μs)\n",
              "\t\t\t  \"paddle\" => Trial(260.103 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(834.885 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.759 ms)\n",
              "\t\t\t  \"paddle\" => Trial(900.286 μs)\n",
              "\t  \"bs=1\" => 2-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t  tags: []\n",
              "\t\t  \"forward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(322.889 μs)\n",
              "\t\t\t  \"jl\" => Trial(870.307 μs)\n",
              "\t\t\t  \"paddle\" => Trial(281.409 μs)\n",
              "\t\t  \"backward\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t\t\t  tags: []\n",
              "\t\t\t  \"funcpaddle\" => Trial(937.832 μs)\n",
              "\t\t\t  \"jl\" => Trial(1.958 ms)\n",
              "\t\t\t  \"paddle\" => Trial(968.952 μs)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}