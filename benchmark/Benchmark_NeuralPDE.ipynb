{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PzmKOAh2LZrF"
      },
      "outputs": [],
      "source": [
        "# The Julia boostrap block\n",
        "# This should be run for the first time to install Julia kernel, and then refresh this page (e.g., Ctrl-R)\n",
        "# so that colab will redirect to the installed Julia kernel\n",
        "# and then doing your own work\n",
        "\n",
        "# 1. install latest Julia using jill.py\n",
        "#    tip: one can install specific Julia version using e.g., `jill install 1.7`\n",
        "!pip install jill && jill install --upstream Official --confirm\n",
        "# 2. install IJulia kernel\n",
        "! julia -e 'using Pkg; pkg\"add IJulia, PyCall, CUDA, PyCallChainRules, NeuralPDE, Flux, DiffEqFlux, GalacticOptim, Quadrature, Cubature, Optimisers, ModelingToolkit, BenchmarkTools, https://github.com/songjhaha/PaddleChainRules.jl.git\"; using IJulia; installkernel(\"Julia\")'\n",
        "# 3. hot-fix patch to strip the version suffix of the installed kernel so that this notebook kernelspec is version agnostic\n",
        "!jupyter kernelspec install $(jupyter kernelspec list | grep julia | tr -s ' ' | cut -d' ' -f3) --replace --name julia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofLDl9-FNxN4"
      },
      "outputs": [],
      "source": [
        "# this notebook is running on google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqO8ykVmNadM",
        "outputId": "42d72103-c174-4406-ca16-596c8625c3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
            " \u001b[90m [6e4b80f9] \u001b[39mBenchmarkTools v1.3.1\n",
            " \u001b[90m [052768ef] \u001b[39mCUDA v3.9.0\n",
            " \u001b[90m [667455a9] \u001b[39mCubature v1.5.1\n",
            " \u001b[90m [aae7a2af] \u001b[39mDiffEqFlux v1.45.3\n",
            " \u001b[90m [587475ba] \u001b[39mFlux v0.12.10\n",
            " \u001b[90m [a75be94c] \u001b[39mGalacticOptim v2.5.0\n",
            " \u001b[90m [7073ff75] \u001b[39mIJulia v1.23.3\n",
            " \u001b[90m [961ee093] \u001b[39mModelingToolkit v8.7.0\n",
            " \u001b[90m [315f7962] \u001b[39mNeuralPDE v4.6.0\n",
            " \u001b[90m [3bd65402] \u001b[39mOptimisers v0.2.1\n",
            " \u001b[90m [b8d414a4] \u001b[39mPaddleChainRules v0.1.0 `https://github.com/songjhaha/PaddleChainRules.jl.git#main`\n",
            " \u001b[90m [438e738f] \u001b[39mPyCall v1.93.1\n",
            " \u001b[90m [b12ccfe2] \u001b[39mPyCallChainRules v0.3.2\n",
            " \u001b[90m [67601950] \u001b[39mQuadrature v1.12.0\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "Pkg.status()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erJ7bkEtLrCF",
        "outputId": "41ae8b08-ae1a-4616-d379-5177db324977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddlepaddle-gpu\n",
            "  Downloading paddlepaddle_gpu-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (435.4 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (3.17.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (1.21.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle-gpu) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->paddlepaddle-gpu) (3.0.4)\n",
            "Installing collected packages: paddlepaddle-gpu\n",
            "Successfully installed paddlepaddle-gpu-2.2.2\n",
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1637.0 MB)\n",
            "Collecting functorch\n",
            "  Downloading functorch-0.1.1-cp37-cp37m-manylinux1_x86_64.whl (21.4 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0+cu113) (4.1.1)\n",
            "Installing collected packages: torch, functorch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "Successfully installed functorch-0.1.1 torch-1.11.0+cu113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tcmalloc: large alloc 1147494400 bytes == 0x55b6b8076000 @  0x7fe0ae5c5615 0x55b67f60a17c 0x55b67f6ea47a 0x55b67f60cf9d 0x55b67f6fed4d 0x55b67f680ec8 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f680d30 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f60ece9 0x55b67f652579 0x55b67f60d902 0x55b67f680c4d 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67c8f6 0x55b67f60e7aa 0x55b67f67cb4f 0x55b67f67ba2e\n",
            "tcmalloc: large alloc 1434370048 bytes == 0x55b6fc6cc000 @  0x7fe0ae5c5615 0x55b67f60a17c 0x55b67f6ea47a 0x55b67f60cf9d 0x55b67f6fed4d 0x55b67f680ec8 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f680d30 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f60ece9 0x55b67f652579 0x55b67f60d902 0x55b67f680c4d 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67c8f6 0x55b67f60e7aa 0x55b67f67cb4f 0x55b67f67ba2e\n",
            "tcmalloc: large alloc 1792966656 bytes == 0x55b6814fe000 @  0x7fe0ae5c5615 0x55b67f60a17c 0x55b67f6ea47a 0x55b67f60cf9d 0x55b67f6fed4d 0x55b67f680ec8 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f680d30 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f6ffb76 0x55b67f67cd95 0x55b67f60ece9 0x55b67f652579 0x55b67f60d902 0x55b67f680c4d 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67c8f6 0x55b67f60e7aa 0x55b67f67cb4f 0x55b67f67ba2e\n",
            "tcmalloc: large alloc 1636958208 bytes == 0x55b6ec2e6000 @  0x7fe0ae5c41e7 0x55b67f640407 0x55b67f60a17c 0x55b67f6ea47a 0x55b67f60cf9d 0x55b67f6fed4d 0x55b67f680ec8 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f60e7aa 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e\n",
            "tcmalloc: large alloc 2046197760 bytes == 0x55b74dc06000 @  0x7fe0ae5c5615 0x55b67f60a17c 0x55b67f6ea47a 0x55b67f60cf9d 0x55b67f6fed4d 0x55b67f680ec8 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67cb4f 0x55b67f60e7aa 0x55b67f67cb4f 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e 0x55b67f60e88a 0x55b67f67d719 0x55b67f67ba2e 0x55b67f60ef21\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.11.0+cu113 which is incompatible.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4m/usr/bin/python3\u001b[24m \u001b[4m-m\u001b[24m \u001b[4mpip\u001b[24m \u001b[4minstall\u001b[24m \u001b[4mtorch==1.11.0+cu113\u001b[24m \u001b[4m-f\u001b[24m \u001b[4mhttps://download.pytorch.org/whl/cu113/torch_stable.html\u001b[24m \u001b[4mfunctorch\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "using PyCall\n",
        "# install paddle-gpu\n",
        "run(`$(PyCall.pyprogramname) -m pip install paddlepaddle-gpu`)\n",
        "run(`$(PyCall.pyprogramname) -m pip install torch==1.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html functorch`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWrg3vEGK1EH",
        "outputId": "2a26208b-81ae-445a-91ab-f32b0aba2164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2299.998\n",
            "BogoMIPS:            4599.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4mlscpu\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# cpu information\n",
        "run(`lscpu`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnFliSRuL0s1",
        "outputId": "65a1d0fb-4df6-4e64-b420-1eb707cae542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 16 05:28:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Process(`\u001b[4mnvidia-smi\u001b[24m`, ProcessExited(0))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# gpu information\n",
        "run(`nvidia-smi`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20utWs3aAYCK",
        "outputId": "23719424-4e24-48a5-c070-0c44b4eb0955"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PDESystem\n",
              "Equations: Equation[Differential(x)(Differential(x)(u(x, y))) + Differential(y)(Differential(y)(u(x, y))) ~ -sin(πx)*sin(πy)]\n",
              "Boundary Conditions: Equation[u(0, y) ~ 0.0, u(1, y) ~ -1.2246467991473532e-16sin(πy), u(x, 0) ~ 0.0, u(x, 1) ~ -1.2246467991473532e-16sin(πx)]\n",
              "Domain: Symbolics.VarDomainPairing[Symbolics.VarDomainPairing(x, 0.0..1.0), Symbolics.VarDomainPairing(y, 0.0..1.0)]\n",
              "Dependent Variables: Num[u(x, y)]\n",
              "Independent Variables: Num[x, y]\n",
              "Parameters: SciMLBase.NullParameters()\n",
              "Default Parameter ValuesDict{Any, Any}()"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "using PaddleChainRules.Paddle: paddle, PaddleModuleWrapper\n",
        "using PyCallChainRules.Torch: TorchModuleWrapper, torch\n",
        "using CUDA\n",
        "using NeuralPDE, Flux, ModelingToolkit, GalacticOptim, DiffEqFlux\n",
        "using Quadrature, Cubature, Optimisers\n",
        "import ModelingToolkit: Interval, infimum, supremum\n",
        "\n",
        "using BenchmarkTools\n",
        "\n",
        "@parameters x y\n",
        "@variables u(..)\n",
        "Dxx = Differential(x)^2\n",
        "Dyy = Differential(y)^2\n",
        "\n",
        "# 2D PDE\n",
        "eq  = Dxx(u(x,y)) + Dyy(u(x,y)) ~ -sin(pi*x)*sin(pi*y)\n",
        "\n",
        "# Boundary conditions\n",
        "bcs = [u(0,y) ~ 0.0, u(1,y) ~ -sin(pi*1)*sin(pi*y),\n",
        "       u(x,0) ~ 0.0, u(x,1) ~ -sin(pi*x)*sin(pi*1)]\n",
        "# Space and time domains\n",
        "domains = [x ∈ Interval(0.0,1.0),\n",
        "           y ∈ Interval(0.0,1.0)]\n",
        "\n",
        "\n",
        "# pde system\n",
        "@named pde_system = PDESystem(eq,bcs,domains,[x,y],[u(x, y)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_HXk42GAbwQ",
        "outputId": "0e81177f-2f17-4ad5-de0e-9b9fe79cbcd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "solve_neuralpde! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ],
      "source": [
        "function solve_neuralpde!(s, hiddendim, pde_system, device; samples=100, evals=10)\n",
        "    paddle.set_default_dtype(\"float64\")\n",
        "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "\n",
        "    if device == \"cuda\"\n",
        "        paddle.device.set_device(\"gpu:0\")\n",
        "    else\n",
        "        paddle.device.set_device(\"cpu\")\n",
        "    end\n",
        "\n",
        "    paddleNN = paddle.nn.Sequential(\n",
        "        paddle.nn.Linear(2, hiddendim),\n",
        "        paddle.nn.Sigmoid(),\n",
        "        paddle.nn.Linear(hiddendim, hiddendim),\n",
        "        paddle.nn.Sigmoid(),\n",
        "        paddle.nn.Linear(hiddendim, 1)\n",
        "    )\n",
        "    paddlewrap = PaddleModuleWrapper(paddleNN)\n",
        "    \n",
        "    torchNN = torch.nn.Sequential(\n",
        "        torch.nn.Linear(2, hiddendim),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(hiddendim, hiddendim),\n",
        "        torch.nn.Sigmoid(),\n",
        "        torch.nn.Linear(hiddendim, 1)\n",
        "    )\n",
        "\n",
        "    if device == \"cuda\"\n",
        "        torchNN = torchNN.to(device=torch.device(\"cuda:0\"))\n",
        "    else\n",
        "        torchNN = torchNN.to(device=torch.device(\"cpu\"))\n",
        "    end\n",
        "\n",
        "    torchwrap = TorchModuleWrapper(torchNN)\n",
        "    \n",
        "    FluxNN = Chain(\n",
        "        Dense(2,hiddendim,Flux.σ),\n",
        "        Dense(hiddendim,hiddendim,Flux.σ),\n",
        "        Dense(hiddendim,1)\n",
        "    )\n",
        "\n",
        "\n",
        "    paddleinitθ, _ = Optimisers.destructure(paddlewrap)\n",
        "    torchinitθ, _ = Optimisers.destructure(torchwrap)\n",
        "    Fluxinitθ, _ = Optimisers.destructure(FluxNN)\n",
        "\n",
        "    if device == \"cuda\"\n",
        "        Fluxinitθ = CuArray(Float64.(Fluxinitθ))\n",
        "    else\n",
        "        Fluxinitθ = Float64.(Fluxinitθ)\n",
        "    end\n",
        "\n",
        "    if device == \"cuda\"\n",
        "        @assert paddleinitθ isa CuArray{Float64}\n",
        "        @assert torchinitθ isa CuArray{Float64}\n",
        "        @assert Fluxinitθ isa CuArray{Float64}\n",
        "    else\n",
        "        @assert paddleinitθ isa Array{Float64}\n",
        "        @assert torchinitθ isa Array{Float64}\n",
        "        @assert Fluxinitθ isa Array{Float64}\n",
        "    end\n",
        "\n",
        "    paddlediscretization = PhysicsInformedNN(paddlewrap, GridTraining(0.1),init_params = paddleinitθ)\n",
        "    prob_paddle = discretize(pde_system,paddlediscretization)\n",
        "\n",
        "    torchdiscretization = PhysicsInformedNN(torchwrap, GridTraining(0.1),init_params = torchinitθ)\n",
        "    prob_torch = discretize(pde_system,torchdiscretization)\n",
        "\n",
        "    Fluxdiscretization = PhysicsInformedNN(FluxNN, GridTraining(0.1),init_params = Fluxinitθ)\n",
        "    prob_Flux = discretize(pde_system,Fluxdiscretization)\n",
        "\n",
        "    prob_solver(prob) = GalacticOptim.solve(prob, DiffEqFlux.ADAM(0.1);maxiters=10)\n",
        "\n",
        "    b_paddle = @benchmarkable($prob_solver(prob), setup=(prob=$prob_paddle), samples=samples, evals=evals)\n",
        "    b_torch = @benchmarkable($prob_solver(prob), setup=(prob=$prob_torch), samples=samples, evals=evals)\n",
        "    b_Flux = @benchmarkable($prob_solver(prob), setup=(prob=$prob_Flux), samples=samples, evals=evals)\n",
        "\n",
        "    s[\"paddle\"] = b_paddle\n",
        "    s[\"torch\"] = b_torch\n",
        "    s[\"Flux\"] = b_Flux\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwgkdUAEAexJ"
      },
      "outputs": [],
      "source": [
        "hiddendim = 16\n",
        "suite = BenchmarkGroup()\n",
        "\n",
        "for device in [\"cpu\"]\n",
        "    ss = suite[\"$device\"] = BenchmarkGroup()\n",
        "    solve_neuralpde!(ss, hiddendim, pde_system, device)\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paddle.device.get_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjhCy3YpUFxf",
        "outputId": "029b1347-b6d0-454a-9634-bdc2ff0bf9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"cpu\""
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVOLsmbDArGH",
        "outputId": "275891be-3559-4ef5-e67b-452eb4d9a593"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []\n",
              "  \"cpu\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"Flux\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"torch\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ],
      "source": [
        "# take a long time\n",
        "tune!(suite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa-hmGICBJ1Q",
        "outputId": "9384479b-b183-4c11-ba99-e85b610b37a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []\n",
              "  \"cpu\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"Flux\" => Trial(36.633 ms)\n",
              "\t  \"torch\" => Trial(224.266 ms)\n",
              "\t  \"paddle\" => Trial(215.442 ms)"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ],
      "source": [
        "results = run(suite, verbose = false)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hiddendim = 16\n",
        "suite = BenchmarkGroup()\n",
        "\n",
        "for device in [\"cuda\"]\n",
        "    ss = suite[\"$device\"] = BenchmarkGroup()\n",
        "    solve_neuralpde!(ss, hiddendim, pde_system, device)\n",
        "end"
      ],
      "metadata": {
        "id": "REAOhjhkUvxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paddle.device.get_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAFdwxwkU_2G",
        "outputId": "8becdb0a-a0b2-417c-a275-f48e6b6a7090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"gpu:0\""
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a long time\n",
        "tune!(suite)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqKCHQ5sVABY",
        "outputId": "4995f913-6ce3-472a-d018-18f2c9b7fae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []\n",
              "  \"cuda\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"Flux\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"torch\" => Benchmark(evals=1, seconds=5.0, samples=100)\n",
              "\t  \"paddle\" => Benchmark(evals=1, seconds=5.0, samples=100)"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = run(suite, verbose = false)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B_o6f91VAI_",
        "outputId": "9f4521c0-7eac-4c86-e19f-42ac357c18d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1-element BenchmarkTools.BenchmarkGroup:\n",
              "  tags: []\n",
              "  \"cuda\" => 3-element BenchmarkTools.BenchmarkGroup:\n",
              "\t  tags: []\n",
              "\t  \"Flux\" => Trial(166.489 ms)\n",
              "\t  \"torch\" => Trial(401.075 ms)\n",
              "\t  \"paddle\" => Trial(370.607 ms)"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Benchmark_NeuralPDE",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}